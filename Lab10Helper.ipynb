{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #  Q1 & Q2: Setup and Reproducibility\n",
    "# Import required libraries following ISLP conventions\n",
    "import numpy as np, pandas as pd, random, torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pytorch_lightning import seed_everything\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchinfo import summary\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from pathlib import Path\n",
    "\n",
    "# Set seeds for reproducibility across all random number generators\n",
    "# This ensures consistent results across runs\n",
    "seed_everything(57, workers=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "print(\"✓ All libraries imported and seeds set for reproducibility\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae50089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 Part A: Data Preparation - Load and split Wage dataset\n",
    "# Load the Wage dataset from ISLP package\n",
    "from ISLP import load_data\n",
    "Wage = load_data('Wage')\n",
    "\n",
    "# Select features and target as specified\n",
    "# Predictors: year, age, education, jobclass\n",
    "# Target: wage\n",
    "\n",
    "# Encode categorical variables (education and jobclass) using one-hot encoding\n",
    "# This converts categories into binary columns that neural networks can process\n",
    "\n",
    "# Relevant Prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bce6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 Part A (continued): Split data 75/25 and standardize\n",
    "# Split into training (75%) and test (25%) sets\n",
    "# random_state=57 ensures reproducible splits (matching global seed)\n",
    "\n",
    "\n",
    "# Standardize features: subtract mean and divide by std\n",
    "# IMPORTANT: Fit scaler ONLY on training data to prevent data leakage\n",
    "# The test set should be transformed using training statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 Part A (continued): Convert to PyTorch tensors and create data module\n",
    "# Convert numpy arrays to PyTorch tensors with appropriate dtypes\n",
    "# float32 is standard for neural network training (balance of precision and speed)\n",
    "# IMPORTANT: Keep targets as 1D tensors (no reshape) for regression\n",
    "\n",
    "\n",
    "# Create TensorDatasets that pair features with targets\n",
    "\n",
    "\n",
    "# Create SimpleDataModule with 25% validation split and batch size of 64\n",
    "# validation=0.25 means 25% of training data is used for validation\n",
    "# batch_size=64 means the model processes 64 samples at a time\n",
    "from ISLP.torch import SimpleDataModule\n",
    "\n",
    "# Get one batch from training data to verify shapes\n",
    "\n",
    "# Relevant Prints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 Part B: Model Definition - Neural network for wage regression\n",
    "class WageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Feedforward neural network for wage prediction.\n",
    "    \n",
    "    Architecture:\n",
    "      - Input layer: number of features from standardized data\n",
    "      - Hidden layer 1: 64 units with ReLU activation and 30% dropout\n",
    "      - Hidden layer 2: 32 units with ReLU activation and 30% dropout\n",
    "      - Output layer: 1 unit (continuous wage prediction)\n",
    "    \n",
    "    Dropout prevents overfitting by randomly deactivating neurons during training.\n",
    "    ReLU (Rectified Linear Unit) adds non-linearity: f(x) = max(0, x)\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the model with correct input dimension\n",
    "\n",
    "\n",
    "# Test model with one batch to verify output shape\n",
    "# Relevant Prints\n",
    "\n",
    "\n",
    "# Print detailed model summary showing layers, parameters, and output shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 Part C: Training - Train the wage regression model\n",
    "from ISLP.torch import SimpleModule, ErrorTracker\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Create Adam optimizer with learning rate of 0.001 as specified\n",
    "\n",
    "# Create SimpleModule for regression task\n",
    "# SimpleModule.regression() automatically uses MSELoss for loss function\n",
    "# metrics: Mean Absolute Error (more interpretable than MSE)\n",
    "\n",
    "\n",
    "# Setup logging to track training progress\n",
    "# CSVLogger saves metrics to a CSV file for later analysis\n",
    "# ErrorTracker monitors both training and validation errors\n",
    "\n",
    "\n",
    "# Create PyTorch Lightning Trainer\n",
    "# max_epochs: number of passes through the entire training dataset\n",
    "# logger: saves training history\n",
    "# callbacks: ErrorTracker monitors performance\n",
    "# deterministic: ensures reproducible results\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "# fit() runs the training loop: forward pass, compute loss, backward pass, update weights\n",
    "\n",
    "# Evaluate on test set\n",
    "\n",
    "# Extract and report test MAE (rounded to 2 decimal places)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 Part D: Learning Curve & Interpretation\n",
    "# Load training log from CSV file saved during training\n",
    "# Use the logger's experiment.metrics_file_path to get the correct version path\n",
    "\n",
    "# Extract training and validation MAE across epochs\n",
    "# PyTorch Lightning logs training metrics as 'train_mae_epoch' and validation as 'valid_mae'\n",
    "\n",
    "# Create learning curve plot\n",
    "\n",
    "#Interpretation (print the whole thing cleanly)\n",
    "print(\"\\nInterpretation:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Part A: Data Preparation - Load image dataset\n",
    "# Define image transformations following ISLP conventions\n",
    "# Compose chains multiple transformations together\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),              # Resize all images to 64x64 pixels\n",
    "    transforms.ToTensor(),                     # Convert PIL Image to tensor (0-1 range)\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], # Normalize each RGB channel\n",
    "                        std=[0.5, 0.5, 0.5])   # to range [-1, 1]\n",
    "])\n",
    "\n",
    "# Load datasets using ImageFolder\n",
    "# ImageFolder expects structure: root/class_name/image_files\n",
    "# It automatically assigns labels: 0 for first folder (cats), 1 for second (dogs)\n",
    "train_path = 'cats_vs_dogs_dataset/train'\n",
    "test_path = 'cats_vs_dogs_dataset/test'\n",
    "\n",
    "train_image_dataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "test_image_dataset = datasets.ImageFolder(root=test_path, transform=transform)\n",
    "\n",
    "# Create DataLoaders for batch processing\n",
    "# shuffle=True randomizes training data order each epoch (prevents learning order)\n",
    "# shuffle=False for test set (order doesn't matter for evaluation)\n",
    "\n",
    "# Relevant Prints\n",
    "\n",
    "# Get one batch to verify shapes + print \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Part A (continued): Display 6 sample images with labels\n",
    "# Helper function to denormalize images for display\n",
    "# Our normalization: (x - 0.5) / 0.5, so to reverse: x * 0.5 + 0.5\n",
    "def denormalize(tensor):\n",
    "    \"\"\"Convert normalized tensor back to [0, 1] range for visualization\"\"\"\n",
    "    return tensor * 0.5 + 0.5\n",
    "\n",
    "# Get a batch of images and labels\n",
    "\n",
    "# Create figure with 2 rows, 3 columns\n",
    "\n",
    "#Loop to denormalize and plot \n",
    "\n",
    "plt.suptitle('Sample Images from Cats vs Dogs Dataset', \n",
    "             fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Sample images displayed and saved to 'sample_images.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Part A (continued): Convert to TensorDataset format\n",
    "# SimpleDataModule expects TensorDatasets, so we convert from ImageFolder format\n",
    "\n",
    "# Extract all images and labels from ImageFolder datasets\n",
    "def dataset_to_tensors(dataset):\n",
    "    \"\"\"Convert ImageFolder dataset to tensors\"\"\"\n",
    "    images_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # Create a DataLoader to batch process\n",
    "    loader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "    \n",
    "    # Get all data in one batch\n",
    "    for images, labels in loader:\n",
    "        images_list.append(images)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    return torch.cat(images_list), torch.cat(labels_list)\n",
    "\n",
    "print(\"Converting datasets to tensors...\")\n",
    "train_images, train_labels = dataset_to_tensors(train_image_dataset)\n",
    "test_images, test_labels = dataset_to_tensors(test_image_dataset)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_tensor_dataset = TensorDataset(train_images, train_labels)\n",
    "test_tensor_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "# Create SimpleDataModule with 25% validation split\n",
    "# This will automatically split training data into train/validation\n",
    "\n",
    "#Relevant Prints\n",
    "\n",
    "# Verify batch shape from DataModule\n",
    "\n",
    "#Relevant Prints \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57622b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Part B: Model Definition - Convolutional Neural Network\n",
    "class CatDogCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for binary image classification.\n",
    "    \n",
    "    Architecture:\n",
    "      Conv Block 1:\n",
    "        - Conv2d: 3→16 channels, 3×3 kernel, padding=1 (preserves size)\n",
    "        - ReLU activation\n",
    "        - MaxPool2d: 2×2 (reduces spatial size by half: 64×64 → 32×32)\n",
    "      \n",
    "      Conv Block 2:\n",
    "        - Conv2d: 16→32 channels, 3×3 kernel, padding=1\n",
    "        - ReLU activation\n",
    "        - MaxPool2d: 2×2 (reduces size: 32×32 → 16×16)\n",
    "      \n",
    "      Fully Connected Layers:\n",
    "        - Flatten: 32×16×16 = 8192 → flattened vector\n",
    "        - Linear: 8192 → 128 neurons\n",
    "        - ReLU activation\n",
    "        - Dropout: 30% regularization\n",
    "        - Linear: 128 → 2 (output logits for 2 classes)\n",
    "    \n",
    "    Why CNNs for images?\n",
    "      - Convolutional layers detect spatial patterns (edges, textures, shapes)\n",
    "      - Pooling layers reduce dimensionality while preserving features\n",
    "      - Local connectivity exploits spatial structure unlike fully connected layers\n",
    "    \"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the model\n",
    "\n",
    "# Test with one batch + print output shape \n",
    "\n",
    "#Print model summary\n",
    "\n",
    "# Print detailed model summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Part C: Training - Train the CNN classifier\n",
    "\n",
    "# Create Adam optimizer with learning rate of 0.001 as specified\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Create SimpleModule for classification\n",
    "# num_classes=2: binary classification (cat vs dog)\n",
    "# SimpleModule.classification() automatically uses:\n",
    "#   - loss_fn: CrossEntropyLoss (standard for classification)\n",
    "#   - metrics: Accuracy (percentage of correct predictions)\n",
    "\n",
    "# Setup logging\n",
    "\n",
    "# Create Trainer for CNN\n",
    "\n",
    "# Train the CNN\n",
    "\n",
    "# Evaluate on test set\n",
    "\n",
    "# Extract and report test accuracy (rounded to 2 decimal places)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa993de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Part D: Learning Curve & Interpretation\n",
    "# Load CNN training log from CSV file saved during training\n",
    "\n",
    "# Extract training and validation accuracy\n",
    "\n",
    "# PyTorch Lightning logs training accuracy as 'train_accuracy_epoch' and validation as 'valid_accuracy'\n",
    "\n",
    "# Create learning curve plot\n",
    "\n",
    "# Interpretation (print the whole thing cleanly)\n",
    "print(\"\\nInterpretation:\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
